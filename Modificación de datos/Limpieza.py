"""
FASE DE MODIFICACI√ìN - METODOLOG√çA SEMMA
Test CASM83 - An√°lisis y Limpieza de Datos

Instrucciones:
1. Guarda este archivo como: limpieza_casm83.py
2. Coloca tu archivo Excel en la misma carpeta con nombre: CASM83.xlsx
3. Ejecuta: python limpieza_casm83.py
4. Revisa los archivos generados y el reporte en consola
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# ============================================================
# CONFIGURACI√ìN INICIAL
# ============================================================

# Nombre del archivo de entrada (Excel)
ARCHIVO_ENTRADA = 'CASM83.xlsx'

# Criterio de eliminaci√≥n: % de respuestas en 0
UMBRAL_CEROS = 70  # Eliminar si m√°s del 70% son ceros

# Valores v√°lidos
VALORES_VALIDOS_RESPUESTAS = [0, 1, 2, 3]
VALORES_VALIDOS_GENERO = [0, 1]
TOTAL_PREGUNTAS = 143  # Total de preguntas en CASM83 R2014

# Escalas del CASM83 R2014 (√Åreas vocacionales) - 11 preguntas por escala
ESCALAS_CASM83 = {
    "CCFM":  [1, 14, 27, 40, 53, 66, 79, 92, 105, 118, 131],   # Ciencias F√≠sico-Matem√°ticas (11 items)
    "CCSS":  [2, 15, 28, 41, 54, 67, 80, 93, 106, 119, 132],   # Ciencias Sociales (11 items)
    "CCNA":  [3, 16, 29, 42, 55, 68, 81, 94, 107, 120, 133],   # Ciencias Naturales (11 items)
    "CCCO":  [4, 17, 30, 43, 56, 69, 82, 95, 108, 121, 134],   # Ciencias de la Comunicaci√≥n (11 items)
    "ARTE":  [5, 18, 31, 44, 57, 70, 83, 96, 109, 122, 135],   # Artes (11 items)
    "BURO":  [6, 19, 32, 45, 58, 71, 84, 97, 110, 123, 136],   # Burocracia (11 items)
    "CCEP":  [7, 20, 33, 46, 59, 72, 85, 98, 111, 124, 137],   # Ciencias Econ√≥mico-Pol√≠ticas (11 items)
    "HAA":   [8, 21, 34, 47, 60, 73, 86, 99, 112, 125, 138],   # Humanidades, Arte y Arquitectura (11 items)
    "FINA":  [9, 22, 35, 48, 61, 74, 87, 100, 113, 126, 139],  # Finanzas (11 items)
    "LING":  [10, 23, 36, 49, 62, 75, 88, 101, 114, 127, 140], # Ling√º√≠stica (11 items)
    "JURI":  [11, 24, 37, 50, 63, 76, 89, 102, 115, 128, 141]  # Jur√≠dico (11 items)
}

# Escalas de control de calidad CASM83 R2014
ESCALAS_CONTROL = {
    "VERA":  [12, 25, 38, 51, 64, 77, 90, 103, 116, 129, 142], # Veracidad (11 items)
    "CONS":  [13, 26, 39, 52, 65, 78, 91, 104, 117, 130, 143]  # Consistencia (11 items)
}

# Umbrales de validez seg√∫n normas CASM83 R2014
UMBRAL_VERACIDAD = 5      # M√≠nimo de respuestas v√°lidas en escala de veracidad (ajustado para 11 items)
UMBRAL_CONSISTENCIA = 5   # M√≠nimo de respuestas consistentes (ajustado para 11 items)

# Nombres descriptivos de las escalas
NOMBRES_ESCALAS = {
    "CCFM": "Ciencias F√≠sico-Matem√°ticas",
    "CCSS": "Ciencias Sociales",
    "CCNA": "Ciencias Naturales",
    "CCCO": "Ciencias de la Comunicaci√≥n",
    "ARTE": "Artes",
    "BURO": "Burocracia/Administrativo",
    "CCEP": "Ciencias Econ√≥mico-Pol√≠ticas",
    "HAA": "Humanidades y Arquitectura",
    "FINA": "Finanzas",
    "LING": "Ling√º√≠stica",
    "JURI": "Jur√≠dico"
}

# ============================================================
# FUNCI√ìN 1: CARGA Y EXPLORACI√ìN INICIAL
# ============================================================

def cargar_datos(archivo):
    """Carga el dataset desde Excel y muestra informaci√≥n b√°sica"""
    print("="*70)
    print("FASE 1: CARGA DE DATOS")
    print("="*70)
    
    try:
        # Leer archivo Excel
        df = pd.read_excel(archivo, engine='openpyxl')
        print(f"‚úì Archivo Excel cargado exitosamente")
        print(f"‚úì Dimensiones: {df.shape[0]} filas x {df.shape[1]} columnas")
        print(f"‚úì Columnas: {list(df.columns[:5])}... (mostrando primeras 5)")
        
        # Verificar preguntas disponibles
        preguntas_cols = [col for col in df.columns if col.startswith('Pregunta_')]
        max_pregunta = max([int(col.split('_')[1]) for col in preguntas_cols]) if preguntas_cols else 0
        print(f"‚úì Preguntas disponibles: Pregunta_1 hasta Pregunta_{max_pregunta}")
        
        # Advertencia si faltan preguntas
        if max_pregunta < TOTAL_PREGUNTAS:
            print(f"\n‚ö†Ô∏è  ADVERTENCIA: El test completo CASM83 R2014 requiere {TOTAL_PREGUNTAS} preguntas")
            print(f"   Tu dataset solo tiene {max_pregunta} preguntas")
            print(f"   Se usar√°n solo las preguntas disponibles para el c√°lculo de escalas")
        
        return df
    except FileNotFoundError:
        print(f"‚úó ERROR: No se encontr√≥ el archivo '{archivo}'")
        print(f"  Aseg√∫rate de tener el archivo Excel en la misma carpeta que este script")
        return None
    except ImportError:
        print(f"‚úó ERROR: Falta la biblioteca 'openpyxl' para leer archivos Excel")
        print(f"  Inst√°lala ejecutando: pip install openpyxl")
        return None
    except Exception as e:
        print(f"‚úó ERROR al cargar el archivo: {str(e)}")
        return None

# ============================================================
# FUNCI√ìN 2B: VALIDACI√ìN DE VERACIDAD Y CONSISTENCIA (CASM83 R2014)
# ============================================================

def evaluar_veracidad_consistencia(df):
    """Eval√∫a las escalas de control seg√∫n normas CASM83 R2014"""
    print("\n" + "="*70)
    print("FASE 2B: VALIDACI√ìN DE VERACIDAD Y CONSISTENCIA (CASM83 R2014)")
    print("="*70)
    
    # Calcular puntajes de Veracidad (solo preguntas disponibles)
    cols_vera = [f'Pregunta_{p}' for p in ESCALAS_CONTROL["VERA"] if f'Pregunta_{p}' in df.columns]
    items_vera_disponibles = len(cols_vera)
    df['puntaje_veracidad'] = df[cols_vera].apply(
        lambda row: sum(val if val in [1, 2, 3] else 0 for val in row), axis=1
    )
    
    # Calcular puntajes de Consistencia (solo preguntas disponibles)
    cols_cons = [f'Pregunta_{p}' for p in ESCALAS_CONTROL["CONS"] if f'Pregunta_{p}' in df.columns]
    items_cons_disponibles = len(cols_cons)
    df['puntaje_consistencia'] = df[cols_cons].apply(
        lambda row: sum(val if val in [1, 2, 3] else 0 for val in row), axis=1
    )
    
    print(f"\nüìã √çtems de control disponibles:")
    print(f"  ‚Ä¢ Veracidad: {items_vera_disponibles}/{len(ESCALAS_CONTROL['VERA'])} √≠tems")
    print(f"  ‚Ä¢ Consistencia: {items_cons_disponibles}/{len(ESCALAS_CONTROL['CONS'])} √≠tems")
    
    # Ajustar umbrales proporcionalmente si no hay todos los √≠tems
    umbral_vera_ajustado = int(UMBRAL_VERACIDAD * items_vera_disponibles / len(ESCALAS_CONTROL['VERA']))
    umbral_cons_ajustado = int(UMBRAL_CONSISTENCIA * items_cons_disponibles / len(ESCALAS_CONTROL['CONS']))
    
    if items_vera_disponibles < len(ESCALAS_CONTROL['VERA']) or items_cons_disponibles < len(ESCALAS_CONTROL['CONS']):
        print(f"\n‚ö†Ô∏è  Umbrales ajustados proporcionalmente:")
        print(f"  ‚Ä¢ Veracidad: {umbral_vera_ajustado} (original: {UMBRAL_VERACIDAD} para 11 √≠tems)")
        print(f"  ‚Ä¢ Consistencia: {umbral_cons_ajustado} (original: {UMBRAL_CONSISTENCIA} para 11 √≠tems)")
    
    # Evaluar validez seg√∫n umbrales ajustados
    df['veracidad_valida'] = df['puntaje_veracidad'] >= umbral_vera_ajustado
    df['consistencia_valida'] = df['puntaje_consistencia'] >= umbral_cons_ajustado
    df['test_valido'] = df['veracidad_valida'] & df['consistencia_valida']
    
    # Estad√≠sticas
    total = len(df)
    invalidos_veracidad = (~df['veracidad_valida']).sum()
    invalidos_consistencia = (~df['consistencia_valida']).sum()
    invalidos_total = (~df['test_valido']).sum()
    
    print(f"\nüìã RESULTADOS DE VALIDACI√ìN:")
    print(f"  ‚Ä¢ Total de registros evaluados: {total}")
    print(f"  ‚Ä¢ Inv√°lidos por VERACIDAD (< {umbral_vera_ajustado} pts): {invalidos_veracidad} ({invalidos_veracidad/total*100:.2f}%)")
    print(f"  ‚Ä¢ Inv√°lidos por CONSISTENCIA (< {umbral_cons_ajustado} pts): {invalidos_consistencia} ({invalidos_consistencia/total*100:.2f}%)")
    print(f"  ‚Ä¢ TOTAL INV√ÅLIDOS: {invalidos_total} ({invalidos_total/total*100:.2f}%)")
    
    if invalidos_total > 0:
        print(f"\n‚ö†Ô∏è  Registros que no cumplen normas CASM83 R2014:")
        invalidos_df = df[~df['test_valido']][['ID', 'puntaje_veracidad', 'puntaje_consistencia', 
                                                 'veracidad_valida', 'consistencia_valida']].head(10)
        for idx, row in invalidos_df.iterrows():
            motivo = []
            if not row['veracidad_valida']:
                motivo.append(f"Veracidad={row['puntaje_veracidad']}/{items_vera_disponibles}")
            if not row['consistencia_valida']:
                motivo.append(f"Consistencia={row['puntaje_consistencia']}/{items_cons_disponibles}")
            print(f"  ‚Ä¢ ID {row['ID']:3.0f}: {', '.join(motivo)}")
        if invalidos_total > 10:
            print(f"  ... y {invalidos_total - 10} m√°s")
    
    return df

def analizar_calidad(df):
    """Analiza la calidad de los datos y detecta problemas"""
    print("\n" + "="*70)
    print("FASE 2: AN√ÅLISIS DE CALIDAD")
    print("="*70)
    
    # Seleccionar solo columnas de preguntas disponibles
    preguntas_cols = [col for col in df.columns if col.startswith('Pregunta_')]
    num_preguntas_disponibles = len(preguntas_cols)
    
    print(f"\nüìä Preguntas disponibles para an√°lisis: {num_preguntas_disponibles}/{TOTAL_PREGUNTAS}")
    
    # Calcular porcentaje de ceros por registro (sobre preguntas disponibles)
    df['porcentaje_ceros'] = (df[preguntas_cols] == 0).sum(axis=1) / num_preguntas_disponibles * 100
    df['total_ceros'] = (df[preguntas_cols] == 0).sum(axis=1)
    df['total_respuesta_A'] = (df[preguntas_cols] == 1).sum(axis=1)
    df['total_respuesta_B'] = (df[preguntas_cols] == 2).sum(axis=1)
    df['total_respuesta_ambos'] = (df[preguntas_cols] == 3).sum(axis=1)
    
    # Estad√≠sticas generales
    print("\nüìä ESTAD√çSTICAS GENERALES:")
    print(f"  ‚Ä¢ Promedio de ceros por registro: {df['porcentaje_ceros'].mean():.2f}%")
    print(f"  ‚Ä¢ Mediana de ceros: {df['porcentaje_ceros'].median():.2f}%")
    print(f"  ‚Ä¢ M√°ximo de ceros: {df['porcentaje_ceros'].max():.2f}%")
    
    # Detectar valores fuera de rango
    valores_invalidos = []
    for col in preguntas_cols:
        invalidos = df[~df[col].isin(VALORES_VALIDOS_RESPUESTAS)]
        if not invalidos.empty:
            valores_invalidos.append((col, invalidos))
    
    if valores_invalidos:
        print("\n‚ö†Ô∏è  VALORES INV√ÅLIDOS DETECTADOS:")
        for col, inv in valores_invalidos:
            print(f"  ‚Ä¢ {col}: {inv[col].unique()}")
    else:
        print("\n‚úì Todos los valores est√°n en el rango v√°lido [0, 1, 2, 3]")
    
    return df

# ============================================================
# FUNCI√ìN 3: IDENTIFICAR REGISTROS A ELIMINAR
# ============================================================

def identificar_registros_invalidos(df, umbral):
    """Identifica registros inv√°lidos por m√∫ltiples criterios"""
    print("\n" + "="*70)
    print("FASE 3: IDENTIFICACI√ìN DE REGISTROS INV√ÅLIDOS")
    print("="*70)
    
    print(f"\nüîç CRITERIOS DE ELIMINACI√ìN:")
    print(f"  1. M√°s del {umbral}% de respuestas en 0 (sin inter√©s)")
    print(f"  2. Veracidad < {UMBRAL_VERACIDAD} puntos (respuestas no veraces)")
    print(f"  3. Consistencia < {UMBRAL_CONSISTENCIA} puntos (respuestas inconsistentes)")
    
    # Criterio 1: Exceso de ceros
    invalidos_ceros = df[df['porcentaje_ceros'] > umbral]
    
    # Criterio 2 y 3: Escalas de control
    invalidos_control = df[~df['test_valido']]
    
    # Combinar ambos criterios (uni√≥n)
    ids_invalidos = set(invalidos_ceros['ID'].tolist()) | set(invalidos_control['ID'].tolist())
    registros_invalidos = df[df['ID'].isin(ids_invalidos)].copy()
    
    # Clasificar motivo de eliminaci√≥n
    def clasificar_motivo(row):
        motivos = []
        if row['porcentaje_ceros'] > umbral:
            motivos.append(f"Exceso ceros ({row['porcentaje_ceros']:.1f}%)")
        if not row['veracidad_valida']:
            motivos.append(f"Veracidad baja ({row['puntaje_veracidad']}/{len(ESCALAS_CONTROL['VERA'])})")
        if not row['consistencia_valida']:
            motivos.append(f"Consistencia baja ({row['puntaje_consistencia']}/{len(ESCALAS_CONTROL['CONS'])})")
        return " | ".join(motivos)
    
    registros_invalidos['motivo_eliminacion'] = registros_invalidos.apply(clasificar_motivo, axis=1)
    
    print(f"\nüìã REGISTROS A ELIMINAR: {len(registros_invalidos)}")
    print(f"  ‚Ä¢ Por exceso de ceros: {len(invalidos_ceros)}")
    print(f"  ‚Ä¢ Por control de calidad: {len(invalidos_control)}")
    print(f"  ‚Ä¢ Total √∫nicos: {len(registros_invalidos)}")
    
    if not registros_invalidos.empty:
        print("\n‚ö†Ô∏è  Detalle de registros problem√°ticos:")
        print("-" * 70)
        for idx, row in registros_invalidos.iterrows():
            print(f"  ID {row['ID']:3.0f} | {row['motivo_eliminacion']}")
    
    return registros_invalidos

# ============================================================
# FUNCI√ìN 4: LIMPIEZA Y FILTRADO
# ============================================================

def limpiar_datos(df, registros_invalidos):
    """Elimina registros problem√°ticos"""
    print("\n" + "="*70)
    print("FASE 4: LIMPIEZA DE DATOS")
    print("="*70)
    
    # Guardar tama√±o original
    filas_originales = len(df)
    
    # Eliminar registros inv√°lidos
    ids_eliminar = registros_invalidos['ID'].tolist()
    df_limpio = df[~df['ID'].isin(ids_eliminar)].copy()
    
    # Eliminar columnas auxiliares temporales
    columnas_eliminar = ['porcentaje_ceros', 'total_ceros', 'total_respuesta_A', 
                         'total_respuesta_B', 'total_respuesta_ambos',
                         'puntaje_veracidad', 'puntaje_consistencia',
                         'veracidad_valida', 'consistencia_valida', 'test_valido']
    df_limpio = df_limpio.drop(columns=columnas_eliminar, errors='ignore')
    
    filas_finales = len(df_limpio)
    
    print(f"\n‚úì Registros eliminados: {filas_originales - filas_finales}")
    print(f"‚úì Registros conservados: {filas_finales}")
    print(f"‚úì Tasa de retenci√≥n: {(filas_finales/filas_originales)*100:.2f}%")
    
    return df_limpio

# ============================================================
# FUNCI√ìN 5: CREAR VARIABLES DERIVADAS
# ============================================================

def crear_variables_derivadas(df):
    """Crea nuevas variables √∫tiles para an√°lisis"""
    print("\n" + "="*70)
    print("FASE 5: CREACI√ìN DE VARIABLES DERIVADAS")
    print("="*70)
    
    preguntas_cols = [col for col in df.columns if col.startswith('Pregunta_')]
    num_preguntas_disponibles = len(preguntas_cols)
    
    # ========== VARIABLES DE CONTEO GENERAL ==========
    df['total_ninguno'] = (df[preguntas_cols] == 0).sum(axis=1)
    df['total_opcion_A'] = (df[preguntas_cols] == 1).sum(axis=1)
    df['total_opcion_B'] = (df[preguntas_cols] == 2).sum(axis=1)
    df['total_ambos'] = (df[preguntas_cols] == 3).sum(axis=1)
    
    # Porcentajes generales (sobre preguntas disponibles)
    df['porc_ninguno'] = (df['total_ninguno'] / num_preguntas_disponibles * 100).round(2)
    df['porc_opcion_A'] = (df['total_opcion_A'] / num_preguntas_disponibles * 100).round(2)
    df['porc_opcion_B'] = (df['total_opcion_B'] / num_preguntas_disponibles * 100).round(2)
    df['porc_ambos'] = (df['total_ambos'] / num_preguntas_disponibles * 100).round(2)
    
    # Respuestas v√°lidas (diferente de 0)
    df['respuestas_validas'] = num_preguntas_disponibles - df['total_ninguno']
    df['tasa_completitud'] = (df['respuestas_validas'] / num_preguntas_disponibles * 100).round(2)
    
    # Etiquetas de g√©nero
    df['genero_etiqueta'] = df['Genero'].map({0: 'Femenino', 1: 'Masculino'})
    
    print("‚úì Variables generales creadas:")
    print("  ‚Ä¢ Contadores: total_ninguno, total_opcion_A, total_opcion_B, total_ambos")
    print("  ‚Ä¢ Porcentajes: porc_ninguno, porc_opcion_A, porc_opcion_B, porc_ambos")
    print("  ‚Ä¢ Calidad: respuestas_validas, tasa_completitud")
    print("  ‚Ä¢ Etiquetas: genero_etiqueta")
    
    # ========== PUNTAJES POR ESCALA VOCACIONAL ==========
    print("\n‚úì Calculando puntajes por √°rea vocacional (11 √≠tems por escala)...")
    
    escalas_incompletas = []
    
    for escala, preguntas in ESCALAS_CASM83.items():
        # Columnas correspondientes a esta escala
        cols_escala = [f'Pregunta_{p}' for p in preguntas]
        
        # Filtrar solo las columnas que existen en el dataframe
        cols_existentes = [col for col in cols_escala if col in df.columns]
        items_disponibles = len(cols_existentes)
        
        if items_disponibles < len(preguntas):
            escalas_incompletas.append((escala, items_disponibles, len(preguntas)))
        
        # Calcular puntaje: suma de respuestas donde eligi√≥ A (1), B (2) o Ambos (3)
        df[f'puntaje_{escala}'] = df[cols_existentes].apply(
            lambda row: sum(val if val in [1, 2, 3] else 0 for val in row), axis=1
        )
        
        # Porcentaje de inter√©s en esta √°rea (sobre el m√°ximo posible)
        max_puntaje = items_disponibles * 3  # M√°ximo si todas son "ambos" (3)
        df[f'porc_{escala}'] = ((df[f'puntaje_{escala}'] / max_puntaje) * 100).round(2) if max_puntaje > 0 else 0
    
    if escalas_incompletas:
        print(f"\n‚ö†Ô∏è  Escalas con √≠tems faltantes (se usar√°n los disponibles):")
        for escala, disponibles, total in escalas_incompletas:
            print(f"  ‚Ä¢ {escala}: {disponibles}/{total} √≠tems ({disponibles/total*100:.0f}%)")
    
    # Identificar √°rea dominante (mayor puntaje)
    escalas_puntaje = [f'puntaje_{e}' for e in ESCALAS_CASM83.keys()]
    df['area_dominante'] = df[escalas_puntaje].idxmax(axis=1).str.replace('puntaje_', '')
    df['puntaje_dominante'] = df[escalas_puntaje].max(axis=1)
    
    # Mapear c√≥digo de escala a nombre completo
    df['area_dominante_nombre'] = df['area_dominante'].map(NOMBRES_ESCALAS)
    
    print(f"  ‚Ä¢ Puntajes por escala: {', '.join([f'puntaje_{e}' for e in ESCALAS_CASM83.keys()])}")
    print(f"  ‚Ä¢ Porcentajes por escala: {', '.join([f'porc_{e}' for e in ESCALAS_CASM83.keys()])}")
    print(f"  ‚Ä¢ √Årea dominante identificada para cada estudiante")
    
    return df

# ============================================================
# FUNCI√ìN 6: GENERAR REPORTES
# ============================================================

def generar_reportes(df_original, df_limpio, registros_invalidos):
    """Genera reportes estad√≠sticos y visualizaciones"""
    print("\n" + "="*70)
    print("FASE 6: GENERACI√ìN DE REPORTES")
    print("="*70)
    
    # Reporte de texto
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    nombre_reporte = f'reporte_limpieza_{timestamp}.txt'
    
    with open(nombre_reporte, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("REPORTE DE LIMPIEZA - DATASET CASM83\n")
        f.write("Fase: MODIFICACI√ìN (SEMMA)\n")
        f.write("="*70 + "\n\n")
        
        f.write("1. RESUMEN DE DATOS ORIGINALES\n")
        f.write("-" * 70 + "\n")
        f.write(f"Total de registros: {len(df_original)}\n")
        f.write(f"Total de preguntas: {TOTAL_PREGUNTAS}\n\n")
        
        f.write("2. CRITERIO DE LIMPIEZA\n")
        f.write("-" * 70 + "\n")
        f.write(f"Criterio 1: > {UMBRAL_CEROS}% de respuestas en 0 (sin inter√©s)\n")
        f.write(f"Criterio 2: Veracidad < {UMBRAL_VERACIDAD} puntos (seg√∫n CASM83 R2014)\n")
        f.write(f"Criterio 3: Consistencia < {UMBRAL_CONSISTENCIA} puntos (seg√∫n CASM83 R2014)\n\n")
        
        f.write("3. REGISTROS ELIMINADOS\n")
        f.write("-" * 70 + "\n")
        f.write(f"Total eliminados: {len(registros_invalidos)}\n")
        if not registros_invalidos.empty:
            f.write("\nIDs eliminados (con motivo):\n")
            for idx, row in registros_invalidos.iterrows():
                f.write(f"  - ID {row['ID']}: {row['motivo_eliminacion']}\n")
        f.write("\n")
        
        f.write("4. RESUMEN DE DATOS LIMPIOS\n")
        f.write("-" * 70 + "\n")
        f.write(f"Total de registros: {len(df_limpio)}\n")
        f.write(f"Tasa de retenci√≥n: {(len(df_limpio)/len(df_original)*100):.2f}%\n\n")
        
        f.write("5. ESTAD√çSTICAS DESCRIPTIVAS (DATOS LIMPIOS)\n")
        f.write("-" * 70 + "\n")
        f.write(f"Promedio tasa de completitud: {df_limpio['tasa_completitud'].mean():.2f}%\n")
        f.write(f"Promedio respuestas 'Ninguno': {df_limpio['porc_ninguno'].mean():.2f}%\n")
        f.write(f"Promedio respuestas 'Opci√≥n A': {df_limpio['porc_opcion_A'].mean():.2f}%\n")
        f.write(f"Promedio respuestas 'Opci√≥n B': {df_limpio['porc_opcion_B'].mean():.2f}%\n")
        f.write(f"Promedio respuestas 'Ambos': {df_limpio['porc_ambos'].mean():.2f}%\n\n")
        
        f.write("6. DISTRIBUCI√ìN POR G√âNERO\n")
        f.write("-" * 70 + "\n")
        dist_genero = df_limpio['genero_etiqueta'].value_counts()
        for genero, count in dist_genero.items():
            f.write(f"{genero}: {count} ({count/len(df_limpio)*100:.2f}%)\n")
        f.write("\n")
        
        f.write("7. DISTRIBUCI√ìN POR GRADO\n")
        f.write("-" * 70 + "\n")
        dist_grado = df_limpio['Grado'].value_counts().sort_index()
        for grado, count in dist_grado.items():
            f.write(f"Grado {grado}: {count} ({count/len(df_limpio)*100:.2f}%)\n")
        f.write("\n")
        
        f.write("8. √ÅREAS VOCACIONALES M√ÅS POPULARES\n")
        f.write("-" * 70 + "\n")
        dist_areas = df_limpio['area_dominante_nombre'].value_counts()
        for area, count in dist_areas.items():
            f.write(f"{area}: {count} estudiantes ({count/len(df_limpio)*100:.2f}%)\n")
        f.write("\n")
        
        f.write("9. PUNTAJES PROMEDIO POR √ÅREA VOCACIONAL\n")
        f.write("-" * 70 + "\n")
        for escala, nombre in NOMBRES_ESCALAS.items():
            puntaje_promedio = df_limpio[f'puntaje_{escala}'].mean()
            porc_promedio = df_limpio[f'porc_{escala}'].mean()
            f.write(f"{nombre:35s}: {puntaje_promedio:5.2f} pts ({porc_promedio:5.2f}%)\n")
    
    print(f"‚úì Reporte guardado: {nombre_reporte}")
    
    # Generar visualizaciones
    generar_visualizaciones(df_limpio)
    
    return nombre_reporte

# ============================================================
# FUNCI√ìN 7: VISUALIZACIONES
# ============================================================

def generar_visualizaciones(df):
    """Crea gr√°ficos de an√°lisis"""
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('An√°lisis del Dataset CASM83 - Datos Limpios', fontsize=16, fontweight='bold')
    
    # Gr√°fico 1: Distribuci√≥n de respuestas por tipo
    ax1 = axes[0, 0]
    tipos = ['Ninguno', 'Opci√≥n A', 'Opci√≥n B', 'Ambos']
    promedios = [
        df['porc_ninguno'].mean(),
        df['porc_opcion_A'].mean(),
        df['porc_opcion_B'].mean(),
        df['porc_ambos'].mean()
    ]
    ax1.bar(tipos, promedios, color=['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4'])
    ax1.set_ylabel('Porcentaje Promedio (%)')
    ax1.set_title('Distribuci√≥n Promedio de Tipos de Respuesta')
    ax1.set_ylim(0, max(promedios) * 1.2)
    for i, v in enumerate(promedios):
        ax1.text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')
    
    # Gr√°fico 2: Distribuci√≥n por g√©nero
    ax2 = axes[0, 1]
    dist_genero = df['genero_etiqueta'].value_counts()
    colors = ['#ff6b6b', '#4ecdc4']
    ax2.pie(dist_genero.values, labels=dist_genero.index, autopct='%1.1f%%', 
            colors=colors, startangle=90)
    ax2.set_title('Distribuci√≥n por G√©nero')
    
    # Gr√°fico 3: Distribuci√≥n de tasa de completitud
    ax3 = axes[0, 2]
    ax3.hist(df['tasa_completitud'], bins=20, color='#45b7d1', edgecolor='black', alpha=0.7)
    ax3.axvline(df['tasa_completitud'].mean(), color='red', linestyle='--', 
                linewidth=2, label=f'Media: {df["tasa_completitud"].mean():.1f}%')
    ax3.set_xlabel('Tasa de Completitud (%)')
    ax3.set_ylabel('Frecuencia')
    ax3.set_title('Distribuci√≥n de Tasa de Completitud')
    ax3.legend()
    
    # Gr√°fico 4: Top 5 √Åreas Vocacionales
    ax4 = axes[1, 0]
    dist_areas = df['area_dominante'].value_counts().head(5)
    colores_areas = plt.cm.Set3(range(len(dist_areas)))
    ax4.barh(range(len(dist_areas)), dist_areas.values, color=colores_areas)
    ax4.set_yticks(range(len(dist_areas)))
    ax4.set_yticklabels([NOMBRES_ESCALAS[area] for area in dist_areas.index])
    ax4.set_xlabel('N√∫mero de Estudiantes')
    ax4.set_title('Top 5 √Åreas Vocacionales Dominantes')
    for i, v in enumerate(dist_areas.values):
        ax4.text(v + 0.3, i, str(v), va='center', fontweight='bold')
    
    # Gr√°fico 5: Puntajes promedio por √°rea
    ax5 = axes[1, 1]
    escalas = list(ESCALAS_CASM83.keys())
    puntajes_prom = [df[f'puntaje_{e}'].mean() for e in escalas]
    ax5.bar(range(len(escalas)), puntajes_prom, color='#96ceb4', edgecolor='black')
    ax5.set_xticks(range(len(escalas)))
    ax5.set_xticklabels(escalas, rotation=45, ha='right')
    ax5.set_ylabel('Puntaje Promedio')
    ax5.set_title('Puntaje Promedio por √Årea Vocacional')
    ax5.grid(axis='y', alpha=0.3)
    
    # Gr√°fico 6: Distribuci√≥n por grado
    ax6 = axes[1, 2]
    dist_grado = df['Grado'].value_counts().sort_index()
    ax6.bar(dist_grado.index.astype(str), dist_grado.values, color='#feca57', edgecolor='black')
    ax6.set_xlabel('Grado')
    ax6.set_ylabel('N√∫mero de Estudiantes')
    ax6.set_title('Distribuci√≥n por Grado Acad√©mico')
    for i, v in enumerate(dist_grado.values):
        ax6.text(i, v + 0.5, str(v), ha='center', fontweight='bold')
    
    plt.tight_layout()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    nombre_grafico = f'visualizacion_datos_{timestamp}.png'
    plt.savefig(nombre_grafico, dpi=300, bbox_inches='tight')
    print(f"‚úì Visualizaci√≥n guardada: {nombre_grafico}")
    
    # Crear gr√°fico adicional: Heatmap de √°reas por g√©nero
    crear_heatmap_areas_genero(df)
    
    return nombre_grafico

def crear_heatmap_areas_genero(df):
    """Crea un heatmap de distribuci√≥n de √°reas por g√©nero"""
    
    # Crear tabla cruzada
    tabla = pd.crosstab(df['area_dominante_nombre'], df['genero_etiqueta'])
    
    plt.figure(figsize=(12, 8))
    sns.heatmap(tabla, annot=True, fmt='d', cmap='YlOrRd', cbar_kws={'label': 'Cantidad'})
    plt.title('Distribuci√≥n de √Åreas Vocacionales por G√©nero', fontsize=14, fontweight='bold')
    plt.xlabel('G√©nero')
    plt.ylabel('√Årea Vocacional')
    plt.tight_layout()
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    nombre_heatmap = f'heatmap_areas_genero_{timestamp}.png'
    plt.savefig(nombre_heatmap, dpi=300, bbox_inches='tight')
    print(f"‚úì Heatmap guardado: {nombre_heatmap}")
    plt.close()

# ============================================================
# FUNCI√ìN 8: EXPORTAR DATOS LIMPIOS
# ============================================================

def exportar_datos(df, registros_invalidos):
    """Exporta los datos procesados en Excel y CSV"""
    print("\n" + "="*70)
    print("FASE 7: EXPORTACI√ìN DE DATOS")
    print("="*70)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Exportar dataset limpio en Excel
    archivo_limpio_excel = f'CASM83_limpio_{timestamp}.xlsx'
    df.to_excel(archivo_limpio_excel, index=False, engine='openpyxl')
    print(f"‚úì Dataset limpio guardado (Excel): {archivo_limpio_excel}")
    
    # Tambi√©n exportar en CSV para compatibilidad
    archivo_limpio_csv = f'CASM83_limpio_{timestamp}.csv'
    df.to_csv(archivo_limpio_csv, index=False, encoding='utf-8')
    print(f"‚úì Dataset limpio guardado (CSV): {archivo_limpio_csv}")
    
    # Exportar registros eliminados
    if not registros_invalidos.empty:
        archivo_eliminados = f'registros_eliminados_{timestamp}.xlsx'
        registros_invalidos.to_excel(archivo_eliminados, index=False, engine='openpyxl')
        print(f"‚úì Registros eliminados guardados: {archivo_eliminados}")
    
    return archivo_limpio_excel

# ============================================================
# FUNCI√ìN PRINCIPAL
# ============================================================

def main():
    """Funci√≥n principal que ejecuta todo el proceso"""
    
    print("\n" + "üéØ " * 25)
    print("AN√ÅLISIS Y LIMPIEZA DE DATOS - TEST CASM83")
    print("Metodolog√≠a SEMMA - Fase: MODIFICACI√ìN")
    print("Aplicando normas: CASM83 R2014 (Veracidad y Consistencia)")
    print("üéØ " * 25)
    
    # 1. Cargar datos
    df = cargar_datos(ARCHIVO_ENTRADA)
    if df is None:
        return
    
    # 2. An√°lisis de calidad
    df = analizar_calidad(df)
    
    # 2B. Validaci√≥n de veracidad y consistencia (CASM83 R2014)
    df = evaluar_veracidad_consistencia(df)
    
    # 3. Identificar registros inv√°lidos
    registros_invalidos = identificar_registros_invalidos(df, UMBRAL_CEROS)
    
    # 4. Limpiar datos
    df_limpio = limpiar_datos(df, registros_invalidos)
    
    # 5. Crear variables derivadas
    df_limpio = crear_variables_derivadas(df_limpio)
    
    # 6. Generar reportes
    reporte = generar_reportes(df, df_limpio, registros_invalidos)
    
    # 7. Exportar datos
    archivo_final = exportar_datos(df_limpio, registros_invalidos)
    
    # Resumen final
    print("\n" + "="*70)
    print("‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
    print("="*70)
    print(f"\nüìÅ Archivos generados:")
    print(f"  1. {archivo_final} (dataset limpio)")
    print(f"  2. {reporte} (reporte detallado)")
    print(f"  3. visualizacion_datos_*.png (gr√°ficos)")
    if not registros_invalidos.empty:
        print(f"  4. registros_eliminados_*.csv (IDs eliminados)")
    
    print(f"\nüìä Estad√≠sticas finales:")
    print(f"  ‚Ä¢ Total registros v√°lidos: {len(df_limpio)}")
    print(f"  ‚Ä¢ Promedio de completitud: {df_limpio['tasa_completitud'].mean():.2f}%")
    print(f"  ‚Ä¢ Validados seg√∫n normas CASM83 R2014")
    print(f"  ‚Ä¢ Dataset listo para FASE DE MODELADO")
    
    print("\n" + "üéØ " * 25 + "\n")

# ============================================================
# EJECUTAR PROGRAMA
# ============================================================

if __name__ == "__main__":
    main()